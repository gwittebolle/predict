{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# REQUEST by PREDICT\n",
    "\n",
    "\n",
    "Copy-paste the request created in Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replace the two lines below with the result of your PREDICT request\n",
    "\n",
    "req1 = \" ( source_id == 'CESM2' ) & ( experiment_id == 'ssp585' ) & ( table_id == 'Amon' ) & ( variable_id == 'pr' ) \"\n",
    "req2 = \"{ 'lons':[ -0.368031, 2.264177, 9.186397 ], 'lats':[ 39.445738, 48.827636, 45.458631 ]} \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate environment - it takes several minutes - If you run a second request, there is no need to run this piece of code again.\n",
    "import pip\n",
    "pip.main([\"install\",\"matplotlib\", \"pandas\", \"xarray\", \"zarr\", \"gcsfs\", \"cftime\", \"dask[array]\", \"toolz\", \"nc-time-axis\", \"openpyxl\", \" xlsxwriter\"])\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import zarr\n",
    "import gcsfs\n",
    "import cftime\n",
    "import xlsxwriter\n",
    "import dask\n",
    "import toolz\n",
    "import os\n",
    "import ast\n",
    "\n",
    "\n",
    "xr.set_options(display_style='html')\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Browse Catalog\n",
    "\n",
    "The data catatalog is stored as a CSV file. Here we read it with Pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('https://storage.googleapis.com/cmip6/cmip6-zarr-consolidated-stores.csv')\n",
    "df_ta = df.query(req1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The columns of the dataframe correspond to the CMI6 controlled vocabulary. A beginners' guide to these terms is available in [this document](https://docs.google.com/document/d/1yUx6jr9EdedCOLd--CPdTfGDwEwzPpCF6p1jRmqx-0Q). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load & Extract Data\n",
    "\n",
    "Now we will load a single store using gcsfs, zarr, and xarray."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_out = {}\n",
    "df_assets = {}\n",
    "# Create a Pandas Excel writer using XlsxWriter as the engine.\n",
    "writer = pd.ExcelWriter('dataset_requested.xlsx', engine='xlsxwriter')\n",
    "\n",
    "\n",
    "for i in range(df_ta.shape[0]):\n",
    "    df_inter = []\n",
    "    # this only needs to be created once\n",
    "    gcs = gcsfs.GCSFileSystem(token='anon')\n",
    "\n",
    "    # get the path to a specific zarr store (the first one from the dataframe above)\n",
    "    zstore = df_ta.zstore.values[i]\n",
    "\n",
    "    # create a mutable-mapping-style interface to the store\n",
    "    mapper = gcs.get_mapper(zstore)\n",
    "\n",
    "    # open it using xarray and zarr\n",
    "    ds = xr.open_zarr(mapper, consolidated=True)\n",
    "    print(ds)\n",
    "    \n",
    "    #Get Metadata\n",
    "    ds_attrs = pd.DataFrame.from_dict(ds.attrs, orient ='index')\n",
    "    \n",
    "    #Filter on assets\n",
    "    # intialise data of lists. \n",
    "    df_assets = pd.DataFrame(ast.literal_eval(req2))\n",
    "  \n",
    "    for j in range(len(df_assets)):\n",
    "        print(j)\n",
    "        ds_sample = ds.sel(lon = df_assets[\"lons\"].iloc[[j]], lat = df_assets[\"lats\"].iloc[[j]], method = 'nearest')\n",
    "        #Convert to df\n",
    "        df_1 = ds_sample.to_dataframe().reset_index()\n",
    "        #get data to 2050\n",
    "        df_1 = df_1[:13514]\n",
    "        \n",
    "        if j == 0 :\n",
    "            df_inter = df_1\n",
    "            print(df_inter)\n",
    "        else :\n",
    "            df_inter = df_inter.append(df_1)\n",
    "            print(df_inter)\n",
    "    \n",
    "    #df_inter = df_inter[df_inter.columns[~df_inter.columns.str.contains('bnds')]]\n",
    "    \n",
    "    #Save in excel\n",
    "    ds_attrs.to_excel(writer, sheet_name='Metadata_' + str(i) )\n",
    "    df_inter.to_excel(writer, sheet_name='Raw_Data_' + str(i) )\n",
    "    \n",
    "writer.save()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
